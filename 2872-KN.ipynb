{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f62d20",
   "metadata": {},
   "source": [
    "## Assignment #3: Cross Validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376e4add",
   "metadata": {},
   "source": [
    "## Name: KINZA NISAR\n",
    "## Roll#: 22i-2872\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dbdd97",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af702241",
   "metadata": {},
   "source": [
    "## Project Overview: \n",
    "This project aims to explore the effectiveness of cross-validation (CV) in machine learning to understand whether it helps in minimizing prediction errors. Cross-validation is a statistical method used to estimate the skill of machine learning models. It is commonly used to protect against overfitting in a predictive model, particularly in a case where the amount of data may be limited. In this project, we will apply linear regression to a dataset related to breast cancer, evaluate the model's performance using various error metrics, and then employ cross-validation to assess its impact on these error metrics.\n",
    "\n",
    "By applying linear regression, we will predict the likelihood of breast cancer based on these features. The model's predictive accuracy will be quantified using Mean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE) on the training data. Subsequently, we will implement cross-validation to evaluate if the model's performance is consistent across different subsets of the data. The comparison of error metrics before and after applying cross-validation will reveal whether CV helps in reducing the prediction error, thereby indicating a more robust model that generalizes well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba3b7d",
   "metadata": {},
   "source": [
    "## Dataset overview:\n",
    "The dataset we are using is focused on breast cancer attributes, which is a compilation of observations and measurements related to breast cancer cases. Each entry in the dataset represents a case with a set of predictor variables such as the characteristics of the cell nuclei present in the digital images of a fine needle aspirate (FNA) of a breast mass. The variables include attributes like radius, texture, perimeter, area, smoothness, compactness, and symmetry of the cell nuclei, among others. The target variable is a binary classification indicating the presence or absence of breast cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c02d98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb059d38",
   "metadata": {},
   "source": [
    "## Import necessary libraries and loadind data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95062255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   diagnosis  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from math import sqrt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Breast_cancer_data.csv')  # Load the breast cancer dataset\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11b753",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b21444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any missing values in the dataset\n",
    "missing_values = df.isnull().sum()\n",
    "# If there are any missing values, fill them with the mean of the column\n",
    "df.fillna(df.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0bfe0f",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa05f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "X = df.drop('diagnosis', axis=1)  # Features\n",
    "y = df['diagnosis']                # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b8c2f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness\n",
      "149       13.740         17.91           88.12      585.0          0.07944\n",
      "124       13.370         16.39           86.10      553.5          0.07115\n",
      "421       14.690         13.98           98.22      656.1          0.10310\n",
      "195       12.910         16.33           82.53      516.4          0.07941\n",
      "545       13.620         23.23           87.19      573.2          0.09246\n",
      "..           ...           ...             ...        ...              ...\n",
      "71         8.888         14.64           58.79      244.0          0.09783\n",
      "106       11.640         18.33           75.17      412.5          0.11420\n",
      "270       14.290         16.82           90.30      632.6          0.06429\n",
      "435       13.980         19.62           91.12      599.5          0.10600\n",
      "102       12.180         20.52           77.22      458.7          0.08013\n",
      "\n",
      "[398 rows x 5 columns]      mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness\n",
      "204       12.470         18.60           81.09      481.9          0.09965\n",
      "70        18.940         21.31          123.60     1130.0          0.09009\n",
      "131       15.460         19.48          101.70      748.9          0.10920\n",
      "431       12.400         17.68           81.47      467.8          0.10540\n",
      "540       11.540         14.44           74.65      402.9          0.09984\n",
      "..           ...           ...             ...        ...              ...\n",
      "69        12.780         16.49           81.37      502.5          0.09831\n",
      "542       14.740         25.42           94.70      668.6          0.08275\n",
      "176        9.904         18.06           64.60      302.4          0.09699\n",
      "501       13.820         24.49           92.33      595.9          0.11620\n",
      "247       12.890         14.11           84.95      512.2          0.08760\n",
      "\n",
      "[171 rows x 5 columns] 149    1\n",
      "124    1\n",
      "421    1\n",
      "195    1\n",
      "545    1\n",
      "      ..\n",
      "71     1\n",
      "106    1\n",
      "270    1\n",
      "435    0\n",
      "102    1\n",
      "Name: diagnosis, Length: 398, dtype: int64 204    1\n",
      "70     0\n",
      "131    0\n",
      "431    1\n",
      "540    1\n",
      "      ..\n",
      "69     1\n",
      "542    1\n",
      "176    1\n",
      "501    0\n",
      "247    1\n",
      "Name: diagnosis, Length: 171, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training (70%) and testing (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b0584",
   "metadata": {},
   "source": [
    "\n",
    "## Linear Regression Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf196568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.73108432  0.24998958  0.34341551  0.67907371  0.92144917 -0.48496903\n",
      " -0.18514305  0.38133394  0.62198264  0.93558694  0.65181806  0.45922572\n",
      "  0.65345093  0.15013175  1.00255465 -0.27657866  0.77876228  0.97933693\n",
      "  1.38994846 -0.0708862   0.63537696  0.77334564 -0.27680044  1.13171496\n",
      "  0.91720421  0.56804974  0.90567253  0.85740733  0.74576894  0.08459591\n",
      "  0.8326972   1.00513101  0.98739088  0.75597472  0.97088645  0.9043856\n",
      "  0.50324922  1.14507516  0.25941456  0.50403886  0.93965092  0.32458969\n",
      "  0.79617807  0.91163794  0.66829346  0.91667661  0.89140571  1.04927446\n",
      "  0.77805706  0.92128477  0.29723532 -0.05357702  0.51687832  0.52198484\n",
      "  0.72756316  0.91209916  0.97220931 -0.52054619  0.54180927  1.01906026\n",
      "  0.71648447 -0.0076777  -0.0869619   0.64143067  0.92872953  0.78063041\n",
      "  0.13359099 -0.58619263  0.86011185  0.68322307  0.33073552  0.45775039\n",
      "  0.81575771  0.29044024  1.32067658  0.67369022  0.63286345  0.52750621\n",
      "  1.21256948  0.78943065  0.3023707   1.12717804  0.517764   -0.06979159\n",
      "  0.28898373  0.11623084  0.36091945  0.13912693  0.90352448  0.72290149\n",
      "  0.89523222  0.56338169  0.50919701  0.87480939  0.8124301   1.05046006\n",
      " -0.04322797  0.18124385  1.0568654   0.30808712  0.467619    1.29101114\n",
      "  0.19603878  0.17219415  0.95639165  0.77749626  0.65242325  0.04476589\n",
      "  0.6203875   0.71076449  0.4888252   0.92555137  0.4883973  -0.04593645\n",
      "  1.07658355 -0.41365245  1.39067565  0.82530806  0.9902121   0.15970083\n",
      "  0.55917757  0.97000016  0.90944567  0.06212365  0.77309894  0.07946394\n",
      "  0.36535155  1.15612544  0.88779677  0.00834586  0.14905861  0.03099058\n",
      "  0.89333748  0.93578966  0.79167111  0.40578584  0.56093926  0.8927348\n",
      "  0.4733761   0.49881958  0.87701865  0.12268172  1.13329291  1.11542464\n",
      "  0.46588424  0.90579763  0.03072962  0.08475502  0.46485618  0.79907144\n",
      "  0.52331932  0.98661497  1.40005483  0.64538712  0.95170014 -0.47983707\n",
      " -0.03325311  1.57190797  0.67796085  1.11311086  1.34372841  1.21627428\n",
      "  1.17724488  0.79618737  0.42619177  1.04759237  0.80956593  0.53168824\n",
      "  1.02997015  0.2663699   0.85219907]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr = LinearRegression()\n",
    "# Fit the model on the training data\n",
    "lr.fit(X_train, y_train)\n",
    "# Predict the target variable for the testing set\n",
    "y_pred = lr.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e86f68",
   "metadata": {},
   "source": [
    "## Evaluation Metrics on Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "137e1ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08433777691869977 0.23466260384148993 0.29040967084224273\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE, MAE, and RMSE on the training dataset\n",
    "mse = mean_squared_error(y_train, lr.predict(X_train))\n",
    "mae = mean_absolute_error(y_train, lr.predict(X_train))\n",
    "rmse = sqrt(mse)\n",
    "print(mse, mae, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7facac9e",
   "metadata": {},
   "source": [
    "\n",
    "## Cross-Validation with Varying K values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ec93cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63691324 0.59130479 0.6736495  0.60304344 0.56079336]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform cross-validation with different values of K\n",
    "cv_scores = cross_val_score(lr, X_train, y_train, cv=5)\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5648d1",
   "metadata": {},
   "source": [
    "\n",
    "## Re-evaluation Metrics on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6921a2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0895557172956861 0.2426183336959684 0.2992586127343474\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reassess the performance on the training dataset after cross-validation\n",
    "mse_cv = -cross_val_score(lr, X_train, y_train, scoring='neg_mean_squared_error', cv=5).mean()\n",
    "mae_cv = -cross_val_score(lr, X_train, y_train, scoring='neg_mean_absolute_error', cv=5).mean()\n",
    "rmse_cv = sqrt(mse_cv)\n",
    "print(mse_cv, mae_cv, rmse_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e60d53",
   "metadata": {},
   "source": [
    "## Compare the error metrics before and after cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a845460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (without CV): 0.08433777691869977 \n",
      "MSE (with CV): 0.0895557172956861\n",
      "MAE (without CV): 0.23466260384148993 \n",
      "MAE (with CV): 0.2426183336959684\n",
      "RMSE (without CV): 0.29040967084224273 \n",
      "RMSE (with CV): 0.2992586127343474\n"
     ]
    }
   ],
   "source": [
    "print('MSE (without CV):', mse, '\\nMSE (with CV):', mse_cv)\n",
    "print('MAE (without CV):', mae, '\\nMAE (with CV):', mae_cv)\n",
    "print('RMSE (without CV):', rmse, '\\nRMSE (with CV):', rmse_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b74fcf",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "The results from the linear regression analysis on the Breast Cancer dataset indicate a slight increase in error metrics when cross-validation (CV) is applied compared to the initial training set without CV. Here's a detailed interpretation of each metric:\n",
    "\n",
    "### MSE (Mean Squared Error): \n",
    "The MSE without CV is approximately 0.0843, and with CV, it is approximately 0.0896. MSE measures the average of the squares of the errors, that is, the average squared difference between the estimated values and the actual value. A lower MSE indicates a better fit of the model to the data. The increase in MSE with CV suggests that when the model is validated across different subsets of the data, the average error increases slightly, indicating a decrease in model performance.\n",
    "\n",
    "### MAE (Mean Absolute Error): \n",
    "The MAE without CV is around 0.2347, and with CV, it is around 0.2426. MAE measures the average magnitude of the errors in a set of predictions, without considering their direction. It's the average over the test sample of the absolute differences between prediction and actual observation. The increase in MAE with CV indicates that the model's predictions are, on average, slightly further away from the actual values when cross-validation is used.\n",
    "\n",
    "### RMSE (Root Mean Squared Error): \n",
    "The RMSE without CV is approximately 0.2904, and with CV, it is approximately 0.2993. RMSE is the square root of the mean of the squared differences between prediction and actual observation. It provides a measure of how well the model's predictions are spread out from the actual values. The increase in RMSE with CV suggests that the spread of the residuals (errors) is larger when the model is subjected to cross-validation.\n",
    "\n",
    "The increase in error metrics with cross-validation is indicative of a model that is slightly overfitting to the training data. Without CV, the model is evaluated on the same data it was trained on, which can lead to an overly optimistic assessment of its performance. Cross-validation, by contrast, assesses the model's ability to perform on different subsets of the data, providing a more realistic evaluation of its predictive power.\n",
    "\n",
    "In conclusion, while the non-CV metrics might look better because they are lower, the CV metrics provide a more honest assessment of the model's performance on unseen data. The slight increase in errors with CV is expected and indicates that the model's performance is consistent across different subsets of the data, which is a desirable property in a predictive model. It suggests that the model is not overly specialized to the training data and has a reasonable level of generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e56328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
